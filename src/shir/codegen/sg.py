from shir import types, layout, config, bit_utils
from shir.codegen.project import SHIRProject
import torch
from torch.fx import GraphModule, Node
from typing import Tuple, List
from pathlib import Path
import shir.codegen.sg_lowering

def fetch_lowering(key):
  return shir.codegen.sg_lowering.fetch_lowering(key)

class Project(SHIRProject):
  def __init__(self, clname: str, output_dir: Path):
    super(Project, self).__init__(clname, output_dir)

  def emit_source(self, gm, host_mapping):
    with (self.output_dir / f"{self.clname}.scala").open("w", encoding="utf-8") as f:
      print("""// This file is autogenerated

package backend.hdl.arch
import core._
import core.compile.CompilerPhase
import core.rewrite.RewriteStep
import java.nio.file.Paths""", file=f)

      print(file=f)
      print("object", self.clname, "extends support.GeneratedModel {", file=f)

      print(file=f)
      print("  override val name: String = \"", self.clname, "\"", sep="", file=f)

      print(file=f)
      print("  def main(args: Array[String]): Unit = support.Util.drive(this, args)", file=f)

      print(file=f)
      print("  override def compilerPhase(): CompilerPhase = mem.MemLayoutCompiler.phaseBefore", file=f)

      print("""
  override def generateIR(): Expr = {
    import eqsat.solver._
    import scala.concurrent.duration._
    val e1 = TypeChecker.check(this.generateSGIR())
    val e2 = sg.Preprocessor(e1)
    val mp = sg.ProblemGenerator(e2)
    val sv = IterativeZ3Py().solve(mp, timeout=2.hour).get
    val e3 = sg.Postprocessor(sg.SolutionInstantiator(sv, e2))
    e3
  }""", file=f)

      print("""
  override def extraRewrites(): Seq[(CompilerPhase, RewriteStep)] = {
    import backend.hdl._
    import backend.hdl.arch.device._
    Seq(
      (device.DeviceSpecificCompiler.phaseAfter,
        core.rewrite.RewriteStep(core.rewrite.RewriteAll(), Seq(core.rewrite.Rule("register-funarg-after-arbiter-and-queue", {
          case Let(fptr, body, ArchLambda(p1, MapVector(f, ParamUse(u1), _), _), _)
            if p1.id == u1.id =>
            Let(fptr, body, ArchLambda(p1, Queued(MapVector(f, Registered(ParamUse(u1))), 2)))
        })))),
      (device.DeviceSpecificCompiler.phaseAfter,
        core.rewrite.RewriteStep(core.rewrite.RewriteAll(), Seq(core.rewrite.Rule("register-funarg-before-arbiter", {
          case FunctionCall(ParamUse(fptr), arg, _) if (arg match {
            case MapVector(ArchLambda(p, Registered(ParamUse(u), _), _), _, _) if p.id == u.id => false
            case Registered(_) | Queued(_) => false
            case _ => true
          }) =>
            Registered(FunctionCall(ParamUse(fptr), Registered(arg)))
        })))),
      (device.DeviceSpecificCompiler.phaseAfter,
        core.rewrite.RewriteStep(core.rewrite.RewriteAll(), Seq(core.rewrite.Rule("register-clip-or-round", {
          case ClipInt(e, lo, _) if !e.isInstanceOf[RegisteredExpr] && !e.isInstanceOf[QueuedExpr] =>
            ClipInt(Registered(e), lo)
          case BankersRoundInt(e, hi, _) if !e.isInstanceOf[RegisteredExpr] && !e.isInstanceOf[QueuedExpr] =>
            BankersRoundInt(Queued(e, 2), hi)
        })))),
      (device.DeviceSpecificCompiler.phaseAfter,
        core.rewrite.RewriteStep(core.rewrite.RewriteAll(), Seq(core.rewrite.Rule("register-max", {
          case ArchLambda(p1, MaxInt(Tuple(Seq(in1, in2), _), _), _) =>
            ArchLambda(p1, Queued(MaxInt(Tuple(in1, in2)), 2))
        })))),
      (device.DeviceSpecificCompiler.phaseAfter,
        core.rewrite.RewriteStep(core.rewrite.RewriteAll(), Seq(core.rewrite.Rule("register-mul2add", {
          case ArchLambda(p1, Mul2AddInt(input, _), _) =>
            ArchLambda(p1, Queued(Mul2AddInt(input), 2))
        })))),
      (MapCompiler.phaseAfter,
        core.rewrite.RewriteStep(core.rewrite.RewriteAll(), Seq(core.rewrite.Rule("register-VTS-map", {
          case MapSimpleOrderedStream(f@ ArchLambda(p, body, _), input@ VectorToOrderedStream(_, t: OrderedStreamTypeT), _) if (body match {
            case Registered(ParamUse(u), _) if p.id == u.id => false
            case Queued(ParamUse(u), _, _) if p.id == u.id => false
            case MapVector(ArchLambda(p1, Registered(ParamUse(u1), _), _), ParamUse(u), _) if p1.id == u1.id && p.id == u.id => false
            case MapVector(ArchLambda(p1, Queued(ParamUse(u1), _, _), _), ParamUse(u), _) if p1.id == u1.id && p.id == u.id => false
            case _ => t.et.isInstanceOf[VectorTypeT] && !t.et.asInstanceOf[VectorTypeT].et.isInstanceOf[LogicTypeT]
          }) =>
            MapSimpleOrderedStream(f,
              MapSimpleOrderedStream(Registered.asFunction(),
                input))
        })))),
    )
  }""", file=f)

      print(file=f)
      self._emit_method_load_data(f, gm, host_mapping)

      print(file=f)
      self._emit_method_generate_ir(f, gm, host_mapping)

      print("}", file=f)


  def _emit_method_load_data(self, f, gm, host_mapping):
    print("  override def loadData(folder: String): Predef.Map[String, Seq[Seq[Int]]] = Predef.Map(", file=f)

    output_node = None
    for n in gm.graph.nodes:
      if n.op == "output":
        assert output_node is None, f"Multi-output node not supported"
        assert isinstance(n.args[0], Node), "Multi-valued output node not supported"
        output_node = n.args[0].meta.get("val")
        continue

      # it is either a placeholder or a intermediate node.
      # in either case, consult the host_mapping table.
      if n in host_mapping:
        host_id = host_mapping[n][0]

        # if it is an input, read the values from csv files.
        # otherwise, just create a bunch of 0's (like in the result case)
        if n.op == "placeholder":
          print(
            "    \"", host_id, "\" -> support.Util.readIntCSV(Paths.get(folder, \"",
            host_id, ".csv\").toFile()),",
            sep="", file=f
          )
        else:
          (outer, inner) = layout.reshape_size_to_matrix(n.meta.get("val").shape)
          print(
            "    \"", host_id, "\" -> new support.UniformSeq(new support.UniformSeq(0, ",
            inner, "), ", outer, "),",
            sep="", file=f
          )

    # for the result, we still need to give it some dummy value for simulation
    # to determine the RAM size.
    (outer, inner) = layout.reshape_size_to_matrix(output_node.shape)
    print(
      "    \"result\" -> new support.UniformSeq(new support.UniformSeq(0, ",
      inner, "), ", outer, ")",
      sep="", file=f
    )

    print("  )", file=f)

  def _emit_method_generate_ir(self, f, gm, host_mapping):
    print("  def generateSGIR(): Expr = {", file=f)
    print("    import backend.hdl._", file=f)

    for n in gm.graph.nodes:
      if n.op == "placeholder":
        host_id, real_typ = host_mapping[n]
        ndim = n.meta.get("val").ndim
        shape = [*n.meta.get("val").shape]

        transpose, (h, w) = layout.pack_host_shape(shape)
        shape = [shape[x] for x in transpose]
        itr = layout.inverse_transpose(transpose)

        ttyp = f"sg.TensorType(Seq({h}, {w}), {real_typ.name()})"
        node = f"sg.SolverGuidedInput(\"{host_id}\", {ttyp})"
        node = f"sg.SolverGuidedRebalance(sg.SolverGuidedReshape({node}, Seq({', '.join((str(d) for d in shape))})))"
        node = f"sg.SolverGuidedPermute({node}, Seq({', '.join((str(d) for d in itr))}))"

        print("    val ", n.name, " = TypeChecker.check(", node, ")", sep="", file=f)

      elif n.op == "output":
        [retv] = n.args
        assert isinstance(retv, Node), "Only single node output is allowed"

        annot_typ = types.get_element_type(retv)
        ndim = retv.meta.get("val").ndim
        shape = retv.meta.get("val").shape

        transpose, (h, w) = layout.pack_host_shape(shape)
        conv = f"ResizeInteger.asFunction(types = Seq({annot_typ.bits}))"
        node = f"sg.SolverGuidedMap({ndim})({conv}, {retv.name})"
        node = f"sg.SolverGuidedPermute({node}, Seq({', '.join((str(d) for d in transpose))}))"
        node = f"sg.SolverGuidedReshape(sg.SolverGuidedRebalance({node}), Seq({h}, {w}))"
        print("    TypeChecker.check(sg.SolverGuidedOutput(", node, "))", sep="", file=f)

      elif n.op == "call_function":
        obj = fetch_lowering(n.target)
        expr = obj.lower(*n.args, **n.kwargs)
        print("    val ", n.name, " = TypeChecker.check(sg.SolverGuidedRebalance(", expr, "))", sep="", file=f)

      else:
        assert False, "Unhandled fx node type when emitting"

    print("  }", file=f)

